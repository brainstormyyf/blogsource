---
title: 中小学学生课堂行为跟踪与分析系统需求说明书
date: 2024-02-28T10:34:00+08:00
draft: false
type: docs
nav_weight: 1
linkTitle: 需求分析
authors:
  - YYF
---

<!--more-->


**修订历史**

|版本号|作者|内容提要|发布日期|
|---|---|---|---|
|V1.0|姚艺峰、牟钟庆、杨燕怡、单怡婧、查懿珈、钟莹滢|首次成稿|2023-7-24|

## 1. 名词解释

|**名称**|**说明**|
|---|---|
|视频通道|提供用户使用摄像头或不同教室场景实现课堂行为分析|
|异常行为检测|对学生上课存在的交头接耳、低头、转头等进行目标检测，实现异常行为的标记|
|课堂专注度分析|通过目标检测，进行注意力评估，分析学生上课专注度，实现数据的可视化，直接展现学生课堂的上课状态|
|人脸注册|将课堂上所有学生的人脸数据都进行注册，存储在数据库中，便于课堂的管理|
|动态点名|进行人脸识别与人脸匹配，可以对具体上课人数进行统计，计算课堂出勤率|

## 2. 项目概述

研究课堂中小学学生行为跟踪与分析系统的目的是深入了解学生在课堂教学中的行为表现，通过数据分析和可视化工具识别和解决学生行为问题，以帮助学生更好地参与课堂活动，提高学习成绩和课堂表现，研究课堂学生行为数据的收集、存储、处理和分析方法，评估不同方法的优缺点，为开发有效的课堂学生行为跟踪与分析系统提供技术支持。

开发课堂中小学学生行为跟踪与分析系统，建立学生行为数据的可视化平台，帮助教师更好地了解学生在课堂中的行为问题，为学生提供个性化的干预和支持服务。

## 3. 项目功能及用户范围

![](https://gitee.com/yao_yi_feng/fighouse/raw/master/img/%E6%99%BA%E6%85%A7%E8%AF%BE%E5%A0%82/202402281040164.webp?width=600#center)

图1 学生行为检测系统功能图

|**功能**|**用户类型**|**描述**|
|---|---|---|
|本地视频上传|教师|通过视频或摄像头接口直接上传视频流|
|异常行为检测|教师|对学生上课存在的交头接耳、低头、转头等进行目标检测，实现异常行为的标记|
|课堂专注度分析|教师|通过目标检测，进行注意力评估，分析学生上课专注度，实现数据的可视化，直接展现学生课堂的上课状态|
|人脸注册|教师|将课堂上所有学生的人脸数据都进行注册，存储在数据库中，便于课堂的管理|
|动态点名|教师|进行人脸识别与人脸匹配，可以对具体上课人数进行统计，计算课堂出勤率|
|异常行为图像抓拍|教师|实现截取图片和保存的功能|
|人脸数据库管理|教师|通过人脸注册的学生数据添加到人脸数据库中，教师可根据需要添加/删除学生信息|

## 4. 项目功能详细说明

![](https://gitee.com/yao_yi_feng/fighouse/raw/master/img/%E6%99%BA%E6%85%A7%E8%AF%BE%E5%A0%82/202402281040429.webp?width=500#center)


### 4.1 视频异常检测

课堂异常行为检测是指通过人工智能技术对学生课堂行为进行实时监测和分析，发现学生出现异常行为时及时报警，以便教师及时干预和纠正，提高课堂管理效率和学生学习效果。

该功能包括以下详细介绍：

（1）监测和分析学生课堂行为：通过人工智能技术，对学生课堂行为进行监测和分析，包括坐姿、注意力等方面；

（2）异常行为类型：将动作自主规定为正常、传纸条、低头偷看、东张西望等四种类型，其中后三种行为均属于异常行为；

（3）异常行为记录与统计：系统可以记录学生的异常行为情况，并进行统计分析，以便教师更好地了解学生的课堂表现；

（4）异常行为干预和纠正：教师可以根据系统标记的异常行为，及时干预和纠正学生的异常行为，提高管理效率。。

### 4.2 人脸注册

人脸注册功能模块主要是通过摄像头获取视频流，采用静默活体检测技术，借助开源模型，对视频流的单帧图片进行人脸检测，对检测到的人脸进行活体检测，若大于阈值，则判定为活体，否则为非活体，并检测到的活体存储在人脸数据库中，实现人脸注册功能。教师可以在系统中对学生进行人脸注册。在注册过程中，系统会要求学生面对摄像头进行人脸采集。采集完成后，系统会自动进行人脸检测和活体检测。如果检测结果为活体，学生的人脸信息将被存储在人脸数据库中，完成注册。

该功能包括以下详细介绍：

（1）人脸检测

人脸检测是基于视频流进行的。摄像头采集的视频流会经过人脸检测算法的处理，以便在视频中识别出人脸。常用的人脸检测算法包括基于深度学习的卷积神经网络（CNN）等。这些算法可以识别出人脸的位置、大小和关键点，为后续的活体检测做好准备。

（2） 活体检测

在识别出人脸后，需要对检测到的人脸进行活体检测，以确保获取到的人脸信息是真实的。活体检测通常基于深度学习技术，如卷积神经网络（CNN）等。在检测过程中，系统会分析人脸图像的纹理、颜色、形状等特征，并与预设的活体检测阈值进行比较。如果特征值大于阈值，则判定为活体；否则为非活体。

（3）人脸数据存储

经过人脸检测和活体检测后，检测到的活体人脸信息会被存储在人脸数据库中，以便教师在后续的教学管理中进行身份核实。

（4）人脸信息管理

教师可以在系统中对学生的人脸信息进行管理，包括添加、删除和查询学生人脸信息。当学生信息发生变化时，如转学、退学等，教师可以在系统中对学生的人脸信息进行相应操作。此外，教师还可以通过系统查询学生的人脸信息，了解学生身份是否真实有效。

（5）安全保护

为了保护学生隐私，系统需要采取一定的安全措施。在人脸采集和识别过程中，系统应遵循相关法律法规，确保学生的人脸信息不被泄露。

（6）异常处理

在人脸注册过程中，可能会出现一些异常情况，如学生人脸信息无法识别、学生拒绝参加人脸采集等。针对这些异常情况，系统需提供相应的处理措施，如重新采集人脸信息、手动输入学生信息等，以确保学生身份真实有效。

### 4.3 动态点名

动态点名功能模块为学生通过摄像头完成签到，可多人同时签到，主要借助dlib库实现人脸识别功能，对人脸特征进行提取，在视频流中抓取人脸特征，然后将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别，完成动态点名功能。

该功能包括以下详细介绍：

（1）对视频流进行人脸检测，以识别出参与签到的学生。人脸检测可以基于 dlib 库等开源工具，通过卷积神经网络（CNN）等算法实现。在检测过程中，系统会分析视频流中的每一帧图像，找出其中的人脸，并记录人脸的位置、大小、关键点等信息。

（2）人脸识别。在提取人脸特征后，系统会将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别。常用的距离计算方法包括欧几里得距离、余弦相似度等。如果计算得到的距离小于预设的阈值，则判定为匹配成功，表示学生已签到；否则为匹配失败，表示学生未签到。

### 4.4 课堂专注度分析

课堂专注度分析是指通过人工智能技术对学生上课情况进行实时监测和分析，以便教师及时干预和纠正，提高课堂管理效率和学生学习效果。

该功能包括以下详细介绍：

（1）监测和分析学生课堂行为：通过人工智能技术，对学生课堂专注度进行监测和分析，包括行为、情绪、头部姿态等方面；

（2）专注度分析报告：系统可以根据学生课堂专注度的监测和分析结果，生成专注度分析报告，供教师参考；

（3）专注度记录和统计：系统可以记录每个学生课堂专注度的情况，并进行统计分析，以便教师更好地了解学生的学习状况；

（4）课堂行为干预和纠正：教师可以根据系统专注度记录情况，及时干预和纠正学生的上课状态，提高管理效率。

